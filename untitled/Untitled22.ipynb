{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyO3EL72qsjcrCOcVhGZk0oV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from transformers import GPT2LMHeadModel, GPT2Tokenizer\n","\n","def chat_with_bot(prompt, model, tokenizer):\n","    inputs = tokenizer.encode(prompt, return_tensors='pt')\n","    outputs = model.generate(\n","        inputs,\n","        max_length=150,\n","        temperature=0.7,\n","        top_k=50,\n","        do_sample=True,\n","        num_return_sequences=1,\n","        pad_token_id=tokenizer.eos_token_id\n","    )\n","    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","    return response\n","\n","def main():\n","\n","    model_name = 'gpt2'\n","    tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n","    model = GPT2LMHeadModel.from_pretrained(model_name)\n","\n","    print(\"Chatbot is ready. Type 'exit' to end the chat.\")\n","\n","    while True:\n","\n","        user_input = input(\"You: \")\n","        if user_input.lower() == 'exit':\n","            break\n","\n","        # Generate response\n","        response = chat_with_bot(user_input, model, tokenizer)\n","        print(f\"Bot: {response}\")\n","\n","if __name__ == \"__main__\":\n","    main()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SUDyxseHuVPM","executionInfo":{"status":"ok","timestamp":1724931167614,"user_tz":-330,"elapsed":4702,"user":{"displayName":"gaurav sharma","userId":"14938895319457339719"}},"outputId":"e1ad1db9-b7b7-45fb-ce08-735206e9a8c7"},"execution_count":22,"outputs":[{"name":"stdout","output_type":"stream","text":["Chatbot is ready. Type 'exit' to end the chat.\n","You: exit\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"GyDFKE116UNN"},"execution_count":null,"outputs":[]}]}
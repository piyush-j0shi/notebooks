{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPJqji+0lLcnyK8L8yoJuwz"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import time\n","import os\n","import shutil\n","import tensorflow as tf\n","from tensorflow import optimizers\n","from tensorflow.keras import callbacks\n","from tensorflow.keras import layers\n","from tensorflow.keras import models\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from sklearn.model_selection import train_test_split"],"metadata":{"id":"nAeKPXtw5WiT","executionInfo":{"status":"ok","timestamp":1724518521329,"user_tz":-330,"elapsed":553,"user":{"displayName":"gaurav sharma","userId":"14938895319457339719"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sbSnWBpQFPsO","executionInfo":{"status":"ok","timestamp":1724518428699,"user_tz":-330,"elapsed":1810,"user":{"displayName":"gaurav sharma","userId":"14938895319457339719"}},"outputId":"cea12931-5815-42c1-c7f1-e8255fe9824a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset URL: https://www.kaggle.com/datasets/prasunroy/natural-images\n","License(s): CC-BY-NC-SA-4.0\n","natural-images.zip: Skipping, found more recently modified local copy (use --force to force download)\n"]}],"source":["!kaggle datasets download -d prasunroy/natural-images"]},{"cell_type":"code","source":["!unzip natural-images.zip"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"q_6kTJeVFTLq","executionInfo":{"status":"ok","timestamp":1724518461419,"user_tz":-330,"elapsed":32723,"user":{"displayName":"gaurav sharma","userId":"14938895319457339719"}},"outputId":"675ee627-6f4b-4469-8d31-600ac81df3c3"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Archive:  natural-images.zip\n","replace data/natural_images/airplane/airplane_0000.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "]}]},{"cell_type":"code","source":["def split_dataset(data_dir, train_dir, valid_dir, val_size = 0.2):\n","\n","  if not os.path.exists(train_dir):\n","    os.makedirs(train_dir)\n","  if not os.path.exists(valid_dir):\n","    os.makedirs(valid_dir)\n","\n","  folders = os.listdir(data_dir)\n","\n","  for folder in folders:\n","    folder_path = os.path.join(data_dir, folder)\n","    if not os.path.isdir(folder_path):\n","      continue\n","\n","    images = os.listdir(folder_path)\n","    train_images, valid_images = train_test_split(images, test_size = val_size, random_state = 42)\n","\n","    train_folder = os.path.join(train_dir, folder)\n","    valid_folder = os.path.join(valid_dir, folder)\n","\n","    if not os.path.exists(train_folder):\n","      os.makedirs(train_folder)\n","    if not os.path.exists(valid_folder):\n","      os.makedirs(valid_folder)\n","\n","    for image in train_images:\n","      shutil.copy(os.path.join(folder_path, image), os.path.join(train_folder, image))\n","    for image in valid_images:\n","      shutil.copy(os.path.join(folder_path, image), os.path.join(valid_folder, image))\n","\n","data_dir = 'natural_images'\n","train_dir = 'train'\n","valid_dir = 'valid'\n","\n","split_dataset(data_dir, train_dir, valid_dir, val_size = 0.2)"],"metadata":{"id":"-f1fGGeNLDc1","executionInfo":{"status":"ok","timestamp":1724518478775,"user_tz":-330,"elapsed":817,"user":{"displayName":"gaurav sharma","userId":"14938895319457339719"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["base_dir = 'natural_images'\n","\n","train_dir_0 = os.path.join(base_dir, 'train')\n","valid_dir_0 = os.path.join(base_dir, 'valid')"],"metadata":{"id":"pQGx3XdZOblh","executionInfo":{"status":"ok","timestamp":1724518526308,"user_tz":-330,"elapsed":3,"user":{"displayName":"gaurav sharma","userId":"14938895319457339719"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["train_datagen = ImageDataGenerator(\n","    rescale = 1./255,\n","    # width_shift_range = 0.2,\n","    # height_shift_range = 0.2,\n","    # shear_range = 0.2,\n","    # zoom_range = 0.2,\n","    # fill_mode = 'nearest',\n","    # horizontal_flip = True\n",")\n","\n","valid_datagen = ImageDataGenerator(\n","    rescale = 1/255\n",")\n","\n","train_generator = train_datagen.flow_from_directory(\n","    train_dir_0,\n","    target_size = (150, 150),\n","    batch_size = 32,\n","    class_mode = 'categorical'\n",")\n","\n","valid_generator = valid_datagen.flow_from_directory(\n","    valid_dir_0,\n","    target_size = (150, 150),\n","    batch_size = 32,\n","    class_mode = 'categorical'\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QKNPoHGEOunT","executionInfo":{"status":"ok","timestamp":1724518529915,"user_tz":-330,"elapsed":3,"user":{"displayName":"gaurav sharma","userId":"14938895319457339719"}},"outputId":"d7f7dbbf-ec1e-43ec-e00f-67c02f7ce45d"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 5516 images belonging to 8 classes.\n","Found 1383 images belonging to 8 classes.\n"]}]},{"cell_type":"code","source":["def create_model():\n","    model = models.Sequential([\n","        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n","        layers.MaxPooling2D((2, 2)),\n","        layers.Conv2D(64, (3, 3), activation='relu'),\n","        layers.MaxPooling2D((2, 2)),\n","        layers.Conv2D(128, (3, 3), activation='relu'),\n","        layers.MaxPooling2D((2, 2)),\n","        layers.Flatten(),\n","        layers.Dense(256, activation='relu'),\n","        layers.Dense(8)\n","    ])\n","    return model"],"metadata":{"id":"aglV2R6WPiFv","executionInfo":{"status":"ok","timestamp":1724518534162,"user_tz":-330,"elapsed":4,"user":{"displayName":"gaurav sharma","userId":"14938895319457339719"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["model = create_model()\n","loss = tf.keras.losses.CategoricalCrossentropy(from_logits = True)\n","optimizer = tf.keras.optimizers.Adam()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cSX9A9Mz6IR-","executionInfo":{"status":"ok","timestamp":1724518534162,"user_tz":-330,"elapsed":3,"user":{"displayName":"gaurav sharma","userId":"14938895319457339719"}},"outputId":"9a370c4b-ba2f-4670-da7c-7047e3f2ba2b"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]}]},{"cell_type":"code","source":["lr_scheduler = optimizers.schedules.ExponentialDecay(\n","    initial_learning_rate = 0.0001,\n","    decay_rate = 0.9,\n","    decay_steps = 1000\n",")\n","\n","optimizer = optimizers.Adam(learning_rate = lr_scheduler)"],"metadata":{"id":"iA-IyUrg6q32","executionInfo":{"status":"ok","timestamp":1724518535971,"user_tz":-330,"elapsed":4,"user":{"displayName":"gaurav sharma","userId":"14938895319457339719"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["early_stopping = callbacks.EarlyStopping(\n","    monitor = 'val_loss',\n","    patience = 5\n",")"],"metadata":{"id":"-we7PAJo7P1N","executionInfo":{"status":"ok","timestamp":1724518535971,"user_tz":-330,"elapsed":4,"user":{"displayName":"gaurav sharma","userId":"14938895319457339719"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["num_epochs = 2\n","best_val_loss = float('inf')\n","patience_counter = 0"],"metadata":{"id":"f4thkUDw7ny6","executionInfo":{"status":"ok","timestamp":1724518535971,"user_tz":-330,"elapsed":3,"user":{"displayName":"gaurav sharma","userId":"14938895319457339719"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["import time\n","import tensorflow as tf\n","\n","for epoch in range(num_epochs):\n","    start_time = time.time()\n","\n","    train_loss = 0\n","    train_accuracy = 0\n","    total_train_samples = 0\n","\n","    for image, labels in train_generator:\n","        with tf.GradientTape() as tape:\n","            logits = model(image, training=True)\n","            loss_value = loss(labels, logits)\n","\n","        gradients = tape.gradient(loss_value, model.trainable_variables)\n","        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n","\n","        train_loss += loss_value * image.shape[0]\n","        correct_predictions = tf.reduce_sum(tf.cast(tf.equal(tf.argmax(logits, axis=1), tf.argmax(labels, axis=1)), tf.float32))\n","        train_accuracy += correct_predictions\n","        total_train_samples += image.shape[0]\n","\n","    train_loss /= total_train_samples\n","    train_accuracy /= total_train_samples\n","\n","    val_loss = 0\n","    val_accuracy = 0\n","    total_val_samples = 0\n","\n","    for image, labels in valid_generator:\n","        logits = model(image, training=False)\n","        loss_value = loss(labels, logits)\n","\n","        val_loss += loss_value * image.shape[0]\n","        correct_predictions = tf.reduce_sum(tf.cast(tf.equal(tf.argmax(logits, axis=1), tf.argmax(labels, axis=1)), tf.float32))\n","        val_accuracy += correct_predictions\n","        total_val_samples += image.shape[0]\n","\n","    val_loss /= total_val_samples\n","    val_accuracy /= total_val_samples\n","\n","    epoch_time = time.time() - start_time\n","    print(f'Epoch {epoch + 1}/{num_epochs} - '\n","          f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f} - '\n","          f'Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f} - '\n","          f'Time: {epoch_time:.2f}s')\n","\n","    if val_loss < best_val_loss:\n","        best_val_loss = val_loss\n","        patience_counter = 0\n","    else:\n","        patience_counter += 1\n","        if patience_counter >= early_stopping.patience:\n","            print(\"Early Stopping Triggered.\")\n","            break\n"],"metadata":{"id":"4LOfldW4Xm2u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"BQZZgEkshVKE"},"execution_count":null,"outputs":[]}]}
{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNiqTeGCpEBiwZcM1OBBAE2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"bqU9XjIqNGbt","executionInfo":{"status":"ok","timestamp":1729316546644,"user_tz":-330,"elapsed":4935,"user":{"displayName":"gaurav sharma","userId":"14938895319457339719"}}},"outputs":[],"source":["import torch"]},{"cell_type":"code","source":["class LogisticRegression(torch.nn.Module):\n","  def __init__(self, input_dimension, output_dimension):\n","    super (LogisticRegression, self).__init__()\n","    self.input_dimension = input_dimension\n","    self.output_dimension = output_dimension\n","    self.layer = torch.nn.Linear(self.input_dimension, self.output_dimension)\n","\n","  def forward(self, x):\n","    prediction = torch.sigmoid(self.layer(x))\n","    return prediction\n","\n","model = LogisticRegression(input_dimension = 6, output_dimension = 1)"],"metadata":{"id":"Rf0SZCBmNP11","executionInfo":{"status":"ok","timestamp":1729316546644,"user_tz":-330,"elapsed":17,"user":{"displayName":"gaurav sharma","userId":"14938895319457339719"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["print(model)\n","for parametres in model.parameters():\n","  print(parametres)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CGl2lJEISOTm","executionInfo":{"status":"ok","timestamp":1729316546644,"user_tz":-330,"elapsed":16,"user":{"displayName":"gaurav sharma","userId":"14938895319457339719"}},"outputId":"3cfe0ca5-5117-4c9f-950f-ff7752638f07"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["LogisticRegression(\n","  (layer): Linear(in_features=6, out_features=1, bias=True)\n",")\n","Parameter containing:\n","tensor([[-0.1257, -0.3965,  0.1026, -0.3230,  0.1686, -0.1294]],\n","       requires_grad=True)\n","Parameter containing:\n","tensor([-0.3254], requires_grad=True)\n"]}]},{"cell_type":"markdown","source":["***lazy method which is not recommended to save and load pytorch models.***"],"metadata":{"id":"JTkDKmMQP_Bv"}},{"cell_type":"code","source":["file = 'model.pth'\n","torch.save(model, file)"],"metadata":{"id":"m6CnoULCOHIE","executionInfo":{"status":"ok","timestamp":1729316546645,"user_tz":-330,"elapsed":15,"user":{"displayName":"gaurav sharma","userId":"14938895319457339719"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["load_saved_model = torch.load(file)\n","load_saved_model.eval()\n","\n","print(load_saved_model)\n","for parametres in load_saved_model.parameters():\n","  print(parametres)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vUn9ys0lOYRb","executionInfo":{"status":"ok","timestamp":1729316546645,"user_tz":-330,"elapsed":14,"user":{"displayName":"gaurav sharma","userId":"14938895319457339719"}},"outputId":"a031b8d4-05f1-48c3-fc10-4beef03f9ba9"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["LogisticRegression(\n","  (layer): Linear(in_features=6, out_features=1, bias=True)\n",")\n","Parameter containing:\n","tensor([[-0.1257, -0.3965,  0.1026, -0.3230,  0.1686, -0.1294]],\n","       requires_grad=True)\n","Parameter containing:\n","tensor([-0.3254], requires_grad=True)\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-5-78fd4d7fbf82>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  load_saved_model = torch.load(file)\n"]}]},{"cell_type":"markdown","source":["***method which is recommended to save and load pytorch models.***"],"metadata":{"id":"OZJX7caeSUVD"}},{"cell_type":"code","source":["file = 'model.pth_1'\n","torch.save(model.state_dict(), file)"],"metadata":{"id":"bbpipKk4OtoC","executionInfo":{"status":"ok","timestamp":1729316546645,"user_tz":-330,"elapsed":12,"user":{"displayName":"gaurav sharma","userId":"14938895319457339719"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# In this method we have to define the model again before loading the model\n","# one more thing using this sate_dict() method we can save any dictonary in this function like we saved the model\n","\n","loaded_model = LogisticRegression(input_dimension = 6, output_dimension = 1)\n","loaded_model.load_state_dict(torch.load(file))\n","loaded_model.eval()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ae-epIXyReXZ","executionInfo":{"status":"ok","timestamp":1729316546646,"user_tz":-330,"elapsed":13,"user":{"displayName":"gaurav sharma","userId":"14938895319457339719"}},"outputId":"008a59f1-0521-431a-92cb-ccefcb236a8f"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-7-72c21843d2fe>:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  loaded_model.load_state_dict(torch.load(file))\n"]},{"output_type":"execute_result","data":{"text/plain":["LogisticRegression(\n","  (layer): Linear(in_features=6, out_features=1, bias=True)\n",")"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["for parametres in loaded_model.parameters():\n","  print(parametres)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XpmZe4UxR-2K","executionInfo":{"status":"ok","timestamp":1729316546646,"user_tz":-330,"elapsed":10,"user":{"displayName":"gaurav sharma","userId":"14938895319457339719"}},"outputId":"fc4e058f-d4e0-44d2-fff3-5ac0d8d73b83"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Parameter containing:\n","tensor([[-0.1257, -0.3965,  0.1026, -0.3230,  0.1686, -0.1294]],\n","       requires_grad=True)\n","Parameter containing:\n","tensor([-0.3254], requires_grad=True)\n"]}]},{"cell_type":"markdown","source":["```\n","Thik hai dekhte hai\n","```"],"metadata":{"id":"L0-TM5VnTPjX"}},{"cell_type":"code","source":["# As we know we can save any dictonary in state dict method so if we have an optimizer and learning rate we can save that also.\n","learning_rate = 0.001\n","optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n","print(optimizer.state_dict())"],"metadata":{"id":"4uusFcCaSGQA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1729319491022,"user_tz":-330,"elapsed":4076,"user":{"displayName":"gaurav sharma","userId":"14938895319457339719"}},"outputId":"4f63d7d6-02cc-4b25-d80b-077700aad6cd"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["{'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'maximize': False, 'foreach': None, 'differentiable': False, 'fused': None, 'params': [0, 1]}]}\n"]}]},{"cell_type":"markdown","source":["\n","\n","```\n","Saving checkpoints using state_dict()\n","```\n","\n"],"metadata":{"id":"z4yOetBljm70"}},{"cell_type":"code","source":["checkpoint = {\n","    'epoch' : 90,\n","    'model_state' : model.state_dict(),\n","    'optimizer_state' : optimizer.state_dict()\n","}\n","torch.save(checkpoint, 'checkpoint.pth')"],"metadata":{"id":"nRBaSg0Ujwb0","executionInfo":{"status":"ok","timestamp":1729321083856,"user_tz":-330,"elapsed":744,"user":{"displayName":"gaurav sharma","userId":"14938895319457339719"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["loaded_checkpoint = torch.load('checkpoint.pth')\n","epoch = loaded_checkpoint['epoch']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pUO3Nqilj_TX","executionInfo":{"status":"ok","timestamp":1729321084495,"user_tz":-330,"elapsed":3,"user":{"displayName":"gaurav sharma","userId":"14938895319457339719"}},"outputId":"f3e044b2-529c-463d-d9a2-26186c3a2c7e"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-13-9de389a9c2cf>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  loaded_checkpoint = torch.load('checkpoint.pth')\n"]}]},{"cell_type":"code","source":["model = LogisticRegression(input_dimension = 6, output_dimension = 1)\n","optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)"],"metadata":{"id":"t0nWWK8tkTcV","executionInfo":{"status":"ok","timestamp":1729321237806,"user_tz":-330,"elapsed":756,"user":{"displayName":"gaurav sharma","userId":"14938895319457339719"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["model.load_state_dict(checkpoint['model_state'])\n","optimizer.load_state_dict(checkpoint['optimizer_state'])"],"metadata":{"id":"zQ8pJqzSk_cI","executionInfo":{"status":"ok","timestamp":1729321331703,"user_tz":-330,"elapsed":3,"user":{"displayName":"gaurav sharma","userId":"14938895319457339719"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["print(optimizer.state_dict())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mbchveGDlKVZ","executionInfo":{"status":"ok","timestamp":1729321366828,"user_tz":-330,"elapsed":683,"user":{"displayName":"gaurav sharma","userId":"14938895319457339719"}},"outputId":"f8bfb6eb-256b-4a51-e5be-29726b13e558"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["{'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'maximize': False, 'foreach': None, 'differentiable': False, 'fused': None, 'params': [0, 1]}]}\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"bxlPRHAcleC-"},"execution_count":null,"outputs":[]}]}
{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"VwYdmPx13pFD"},"outputs":[],"source":["import os\n","import time\n","import torch\n","import torchvision\n","import numpy as np\n","from PIL import Image\n","from tempfile import TemporaryDirectory"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29563,"status":"ok","timestamp":1728923398474,"user":{"displayName":"gaurav sharma","userId":"14938895319457339719"},"user_tz":-330},"id":"AIbgZJ444ICQ","outputId":"c3d4a252-0a7a-4683-d767-aa103cacd0b1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"9UzKPZaa4R8O"},"outputs":[],"source":["!unzip /content/drive/MyDrive/hymenoptera_data.zip -d /content/data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YT4VZxukBxI7"},"outputs":[],"source":["mean = np.array([0.5, 0.5, 0.5])\n","std = np.array([0.25, 0.25, 0.25])\n","\n","data_transform = {\n","    'train': torchvision.transforms.Compose([\n","        torchvision.transforms.RandomResizedCrop(224),\n","        torchvision.transforms.RandomHorizontalFlip(),\n","        torchvision.transforms.ToTensor(),\n","        torchvision.transforms.Normalize(mean, std)\n","    ]),\n","    'val': torchvision.transforms.Compose([\n","        torchvision.transforms.Resize(256),\n","        torchvision.transforms.CenterCrop(224),\n","        torchvision.transforms.ToTensor(),\n","        torchvision.transforms.Normalize(mean, std)\n","    ]),\n","}"]},{"cell_type":"markdown","metadata":{"id":"CEa14aRTBzL4"},"source":["# ***writing our own custom class***"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xMMFSAaJ4qV2"},"outputs":[],"source":["class CustomData():\n","  def __init__(self, split, root_dir, transform):\n","    self.split = split\n","    self.root_dir = root_dir\n","    self.transform = transform\n","\n","    self.image_path = []\n","    self.image_label = []\n","\n","    self.class_map = {\n","        'ants' : 0,\n","        'bees' : 1\n","    }\n","\n","    self.split_dir = os.path.join(self.root_dir, self.split)\n","    self.load_data()\n","\n","  def load_data(self):\n","    for class_name in os.listdir(self.split_dir):\n","      class_dir = os.path.join(self.split_dir, class_name)\n","      if os.path.isdir(class_dir):\n","        for images in os.listdir(class_dir):\n","          image_dir = os.path.join(class_dir, images)\n","          if images.lower().endswith(('.jpeg', '.png', '.jpg')):\n","            self.image_path.append(image_dir)\n","            self.image_label.append(self.class_map[class_name])\n","\n","  def __len__(self):\n","    return len(self.image_path)\n","\n","  def __getitem__(self, index):\n","    img_path = self.image_path[index]\n","    image = Image.open(img_path).convert('RGB')\n","\n","    if self.transform:\n","      image = self.transform(image)\n","\n","    label = self.image_label[index]\n","    return image, label"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jH-2APvP8dEP"},"outputs":[],"source":["train_dataset = CustomData(\n","    root_dir = '/content/data/hymenoptera_data',\n","    transform = data_transform['train'],\n","    split = 'train'\n",")\n","\n","val_dataset = CustomData(\n","    root_dir = '/content/data/hymenoptera_data',\n","    transform = data_transform['val'],\n","    split = 'val'\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Pb9h98yb82TG"},"outputs":[],"source":["batch_size = 4\n","train_loader = torch.utils.data.DataLoader(\n","    dataset = train_dataset,\n","    batch_size = batch_size,\n","    shuffle = True\n",")\n","\n","val_loader = torch.utils.data.DataLoader(\n","    dataset = val_dataset,\n","    batch_size = batch_size,\n","    shuffle = True\n",")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Sv0uTJMI9IGW"},"outputs":[],"source":["# for input, output in train_loader:\n","#   print('input : ', input.shape)\n","#   print('output : ', output)\n","#   break\n","\n","# print(len(train_dataset))\n","# print(len(val_dataset))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6ehTHlbx_M-V"},"outputs":[],"source":["dataloaders = {\n","    'train' : train_loader,\n","    'val' : val_loader\n","}\n","\n","dataset_sizes = {\n","    'train' : len(train_dataset),\n","    'val' : len(val_dataset)\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25,"status":"ok","timestamp":1728923404732,"user":{"displayName":"gaurav sharma","userId":"14938895319457339719"},"user_tz":-330},"id":"UIknVEMb_2B9","outputId":"6db594e4-80aa-44f5-885f-44cd92abe00c"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'train': 244, 'val': 153}\n","{'train': <torch.utils.data.dataloader.DataLoader object at 0x7e1c9c4816c0>, 'val': <torch.utils.data.dataloader.DataLoader object at 0x7e1c9c482890>}\n"]}],"source":["print(dataset_sizes)\n","print(dataloaders)"]},{"cell_type":"markdown","metadata":{"id":"bMtNloLCBkEE"},"source":["#***Without writing our own custom class***"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ADprV7WrAPEA"},"outputs":[],"source":["train_dataset_1 = torchvision.datasets.ImageFolder(\n","    root = '/content/data/hymenoptera_data/train',\n","    transform = data_transform['train']\n",")\n","\n","val_dataset_1 = torchvision.datasets.ImageFolder(\n","    root = '/content/data/hymenoptera_data/val',\n","    transform = data_transform['val']\n",")\n","\n","batch_size = 4\n","train_loader_1 = torch.utils.data.DataLoader(\n","    dataset = train_dataset_1,\n","    batch_size = batch_size,\n","    shuffle = True\n",")\n","\n","val_loader_1 = torch.utils.data.DataLoader(\n","    dataset = val_dataset_1,\n","    batch_size = batch_size,\n","    shuffle = True\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AyFDD-z3BP1k"},"outputs":[],"source":["dataloaders_1 = {\n","    'train' : train_loader_1,\n","    'val' : val_loader_1\n","}\n","\n","dataset_sizes_1 = {\n","    'train' : len(train_dataset_1),\n","    'val' : len(val_dataset_1)\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1728923404732,"user":{"displayName":"gaurav sharma","userId":"14938895319457339719"},"user_tz":-330},"id":"kwZotFMzBWWk","outputId":"5684f3df-d904-498d-d89e-59bd4429af48"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'train': 244, 'val': 153}\n","{'train': <torch.utils.data.dataloader.DataLoader object at 0x7e1c9c480e80>, 'val': <torch.utils.data.dataloader.DataLoader object at 0x7e1c9c481cc0>}\n"]}],"source":["print(dataset_sizes_1)\n","print(dataloaders_1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fslF7tUBBZma"},"outputs":[],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1728923404732,"user":{"displayName":"gaurav sharma","userId":"14938895319457339719"},"user_tz":-330},"id":"G8OMxOEwzukZ","outputId":"a11eed08-423d-4141-a208-021b856ea698"},"outputs":[{"name":"stdout","output_type":"stream","text":["cpu\n"]}],"source":["print(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"11KlVwTbzvvs"},"outputs":[],"source":["def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n","    since = time.time()\n","\n","    with TemporaryDirectory() as tempdir:\n","        best_model_params_path = os.path.join(tempdir, 'best_model_params.pt')\n","\n","        torch.save(model.state_dict(), best_model_params_path)\n","        best_acc = 0.0\n","\n","        for epoch in range(num_epochs):\n","            print(f'epoch :  {epoch + 1}/{num_epochs}')\n","            print('_' * 40)\n","\n","            for phase in ['train', 'val']:\n","                if phase == 'train':\n","                    model.train()\n","                else:\n","                    model.eval()\n","\n","                running_loss = 0.0\n","                running_corrects = 0\n","\n","                for inputs, labels in dataloaders[phase]:\n","                    inputs = inputs.to(device)\n","                    labels = labels.to(device)\n","\n","                    optimizer.zero_grad()\n","\n","                    with torch.set_grad_enabled(phase == 'train'):\n","                        outputs = model(inputs)\n","                        _, preds = torch.max(outputs, 1)\n","                        loss = criterion(outputs, labels)\n","\n","                        if phase == 'train':\n","                            loss.backward()\n","                            optimizer.step()\n","\n","                    running_loss += loss.item() * inputs.size(0)\n","                    running_corrects += torch.sum(preds == labels.data)\n","                if phase == 'train':\n","                    scheduler.step()\n","\n","                epoch_loss = running_loss / dataset_sizes[phase]\n","                epoch_acc = running_corrects.double() / dataset_sizes[phase]\n","\n","                print(f'{phase} loss: {epoch_loss:.4f} | {phase} acc : {epoch_acc:.4f}')\n","\n","                if phase == 'val' and epoch_acc > best_acc:\n","                    best_acc = epoch_acc\n","                    torch.save(model.state_dict(), best_model_params_path)\n","\n","            print()\n","\n","        time_elapsed = time.time() - since\n","        print(f'Training completed in : {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n","        print(f'Best validation accuracy : {best_acc: 4f}')\n","        print(f'Best training accuracy : {epoch_acc : 4f}')\n","\n","        model.load_state_dict(torch.load(best_model_params_path, weights_only = True))\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1728923404732,"user":{"displayName":"gaurav sharma","userId":"14938895319457339719"},"user_tz":-330},"id":"Lhv4hwVl0PCI","outputId":"cfdab0c7-2a04-42c6-c2c4-b95ad660b9e9"},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n","100%|██████████| 44.7M/44.7M [00:00<00:00, 95.0MB/s]\n"]}],"source":["model_ft = torchvision.models.resnet18(weights = 'IMAGENET1K_V1')\n","num_ftrs = model_ft.fc.in_features\n","model_ft.fc = torch.nn.Linear(num_ftrs, 2)\n","model_ft = model_ft.to(device)\n","criterion = torch.nn.CrossEntropyLoss()\n","optimizer_ft = torch.optim.SGD(model_ft.parameters(), lr = 0.001, momentum = 0.9)\n","exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer_ft, step_size = 7, gamma = 0.1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"CAKSX2Rh0iWR","outputId":"b8531795-36d3-4111-f000-cb953909dcb1"},"outputs":[{"name":"stdout","output_type":"stream","text":["epoch :  1/25\n","________________________________________\n","train loss: 0.5317 | train acc : 0.7418\n","val loss: 0.2296 | val acc : 0.9085\n","\n","epoch :  2/25\n","________________________________________\n","train loss: 0.5575 | train acc : 0.7623\n","val loss: 0.1283 | val acc : 0.9542\n","\n","epoch :  3/25\n","________________________________________\n","train loss: 0.4902 | train acc : 0.7910\n","val loss: 0.3055 | val acc : 0.8954\n","\n","epoch :  4/25\n","________________________________________\n","train loss: 0.8311 | train acc : 0.7418\n","val loss: 0.2588 | val acc : 0.9216\n","\n","epoch :  5/25\n","________________________________________\n","train loss: 0.6513 | train acc : 0.7664\n","val loss: 0.2758 | val acc : 0.8758\n","\n","epoch :  6/25\n","________________________________________\n","train loss: 0.5750 | train acc : 0.7582\n","val loss: 0.3762 | val acc : 0.8693\n","\n","epoch :  7/25\n","________________________________________\n","train loss: 0.5532 | train acc : 0.7992\n","val loss: 0.3213 | val acc : 0.8824\n","\n","epoch :  8/25\n","________________________________________\n","train loss: 0.3769 | train acc : 0.8443\n","val loss: 0.2842 | val acc : 0.9216\n","\n","epoch :  9/25\n","________________________________________\n","train loss: 0.3309 | train acc : 0.8607\n","val loss: 0.2506 | val acc : 0.9281\n","\n","epoch :  10/25\n","________________________________________\n","train loss: 0.2744 | train acc : 0.8852\n","val loss: 0.2649 | val acc : 0.9216\n","\n","epoch :  11/25\n","________________________________________\n","train loss: 0.4352 | train acc : 0.7951\n","val loss: 0.2505 | val acc : 0.9346\n","\n","epoch :  12/25\n","________________________________________\n","train loss: 0.3426 | train acc : 0.8648\n","val loss: 0.2907 | val acc : 0.9216\n","\n","epoch :  13/25\n","________________________________________\n","train loss: 0.3518 | train acc : 0.8525\n","val loss: 0.2504 | val acc : 0.9150\n","\n","epoch :  14/25\n","________________________________________\n","train loss: 0.3410 | train acc : 0.8607\n","val loss: 0.2652 | val acc : 0.9216\n","\n","epoch :  15/25\n","________________________________________\n","train loss: 0.3443 | train acc : 0.8238\n","val loss: 0.2645 | val acc : 0.9281\n","\n","epoch :  16/25\n","________________________________________\n","train loss: 0.2602 | train acc : 0.8934\n","val loss: 0.2764 | val acc : 0.9150\n","\n","epoch :  17/25\n","________________________________________\n","train loss: 0.3015 | train acc : 0.8770\n","val loss: 0.2521 | val acc : 0.9216\n","\n","epoch :  18/25\n","________________________________________\n","train loss: 0.3130 | train acc : 0.8934\n","val loss: 0.2711 | val acc : 0.9150\n","\n","epoch :  19/25\n","________________________________________\n","train loss: 0.2538 | train acc : 0.8975\n","val loss: 0.2533 | val acc : 0.9216\n","\n","epoch :  20/25\n","________________________________________\n","train loss: 0.3635 | train acc : 0.8320\n","val loss: 0.2519 | val acc : 0.9216\n","\n","epoch :  21/25\n","________________________________________\n","train loss: 0.3160 | train acc : 0.8893\n","val loss: 0.2629 | val acc : 0.9150\n","\n","epoch :  22/25\n","________________________________________\n","train loss: 0.1941 | train acc : 0.9344\n","val loss: 0.2678 | val acc : 0.9150\n","\n","epoch :  23/25\n","________________________________________\n","train loss: 0.2707 | train acc : 0.8852\n","val loss: 0.2409 | val acc : 0.9150\n","\n","epoch :  24/25\n","________________________________________\n","train loss: 0.2880 | train acc : 0.8852\n","val loss: 0.2604 | val acc : 0.9216\n","\n","epoch :  25/25\n","________________________________________\n","train loss: 0.3083 | train acc : 0.8648\n","val loss: 0.2591 | val acc : 0.9150\n","\n","Training completed in : 35m 52s\n","Best validation accuracy :  0.954248\n","Best training accuracy :  0.915033\n"]}],"source":["history = train_model(model_ft,\n","                      criterion,\n","                      optimizer_ft,\n","                      exp_lr_scheduler,\n","                      num_epochs = 25\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"qtMEm3r2197l"},"outputs":[],"source":[]}],"metadata":{"accelerator":"TPU","colab":{"gpuType":"V28","provenance":[],"authorship_tag":"ABX9TyO/hKNrMX5BW4Bdp83TFb8O"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}